{
 "metadata": {
  "name": "",
  "signature": "sha256:bd81185cc5a9e00db1c5d74f7997f6c9f2c6a82925dfa4523dc2623b624a633c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Quantitative Textanalyse mit Python"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<b>Aufgabenstellung</b>:\n",
      "\n",
      "- Texte ausw\u00e4hlen und mit Labels versehen\n",
      "- Naive Bayessche Klassifikation\n",
      "- \u00dcberpr\u00fcfung und Tests\n",
      "- Modell interpretieren"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Textvorstellung und Beschreibung des Klassifikationsverfahrens"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Im Folgenden soll eine Sentimentanalyse von Beitr\u00e4gen aus dem sozialen Netzwerk *Twitter* durch ein Naive-Bayes-Klassifikationsverfahren durchgef\u00fchrt werden. Bei der Sentimentanalyse werden Einstellungen in Texten untersucht, um beispielsweise den emotionalen Status darzustellen. So wird in diesem Beispiel anhand der Bedeutung einzelner W\u00f6rter zwischen Beitr\u00e4gen unterschieden, die eher als negativ (z.B. traurig wirkend, bedr\u00fcckend) oder eher als positiv (z.B. gl\u00fccklich, heiter wirkend) eingestuft werden.\n",
      "\n",
      "Daf\u00fcr wurden im Vorfeld \u00fcber die Twitter API insgesamt \u00fcber 28.000 Posts in englischer Sprache gesammelt und durch eine Evaluationsliste f\u00fcr Sentimente in positive und negative Tweets eingeteilt. Die Vorgehensweise f\u00fcr die Belabelung der Tweets ist im Anhang zu diesem Dokument dargestellt. \n",
      "\n",
      "Anhand dieser Bezeichnungen soll ein Naive-Bayes'scher Klassifikator trainiert werden, der auf Basis der Eigenschaften der Tweets f\u00fcr ein Testset die korrekte Einstufung, also *postiv* versus *negativ*, vornehmen soll.\n",
      "Der verwendete Klassifikator basiert auf dem Bayes Theorem, welches in der folgenden Formel abgebildet ist:\n",
      "\n",
      "\\begin{equation}\n",
      " \\Pr(Label|Features)=\\frac{\\Pr(Features|Label) * \\Pr(Label)}{\\Pr(Features)}\n",
      "\\end{equation}\n",
      "\n",
      "So ergibt sich die Wahrscheinlichkeit zur Zugeh\u00f6rigkeit einer Bezeichnung unter der Bedingung bestimmter Eigenschaften aus dem Produkt der Wahrscheinlichkeit f\u00fcr diese Bezeichnung und der Wahrscheinlichkeit der Eigenschaften gegeben die Bezeichnung, dividiert durch die Wahrscheinlichkeit der Eigenschaften. Der Klassifikator w\u00e4hlt eine Bezeichnung so, dass die Wahrscheinlichkeit f\u00fcr diese Bezeichnung gegeben bestimmter Eigenschaften maximiert wird.\n",
      "\n",
      "Der Klassifikator bedingt streng genommen die Annahme, dass die Position eines Wortes in einem Text von allen anderen W\u00f6rtern stochastisch unabh\u00e4ngig ist. Die Erf\u00fcllung dieser Voraussetzung ist f\u00fcr die meisten Texte, eingeschlossen die hier analysierten Beitr\u00e4ge, h\u00f6chst fragw\u00fcrdig. Nichtsdestotrotz liefert der Bayes Klassifikator annehmbare Ergebnisse.\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Vorbereitung"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Zun\u00e4chst werden die mit Labels versehenen, tokenisierten und um Stoppw\u00f6rter bereinigten Tweets geladen. Nach der Einteilung in positive und negative Beitr\u00e4ge verbleiben 15.711 Tweets zur Klassifizierung. F\u00fcr die Eigenschaften zur Klassifizierung werden die 1000 h\u00e4ufigsten Worte, die in allen Tweets vorkommen, bestimmt. Zur Veranschaulichung ist am Ende des folgenden Outputs ein Tweet dargestellt, der vermutlich eher negative Emotionen des Beitragverfassers ausdr\u00fcckt."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "from nltk.classify import apply_features\n",
      "import random\n",
      "import pickle\n",
      "\n",
      "%cd \"E:\\Dropbox\\Soziologie Master\\Quantitative Textanalysen mit Python\\Berichte\\2. Bericht\\\"\n",
      "\n",
      "def loadobject(filename):\n",
      "    with open(filename, 'rb') as f:\n",
      "        output = pickle.load(f)\n",
      "        return output\n",
      "\n",
      "sentiment_tweets = loadobject(\"sentiment_tweets\")\n",
      "sentiment_sets = loadobject(\"sentiment_sets\")\n",
      "\n",
      "print len(sentiment_tweets)\n",
      "print sentiment_tweets[1]\n",
      "\n",
      "def bagofwords(lists):\n",
      "    bow = []\n",
      "    for tweet in lists:\n",
      "            for word in tweet:\n",
      "                bow.append(word)\n",
      "    return bow\n",
      "                       \n",
      "bow = bagofwords(sentiment_tweets)                      \n",
      "all_words = nltk.FreqDist(bow)\n",
      "word_list = all_words.keys()[:1000]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "E:\\Dropbox\\Soziologie Master\\Quantitative Textanalysen mit Python\\Berichte\\2. Bericht\n",
        "15711"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[u'rt', u'egcrimsix', u'need', u'stop', u'raging', u'this', u'stuff', u'bad', u'your', u'health', u'feel', u'like', u'volcano', u'to', u'explode', u'right']\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Extraktion der Texteigenschaften, Anlegung von Trainings- und Testsets"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Nachfolgend wird eine Methode zur Extraktion der Features abgebildet. Die Methode speichert f\u00fcr jeden Tweet und alle Elemente aus der zuvor gebildeten Liste der 1000 h\u00e4ufigsten W\u00f6rter durch eine boolsche Abfrage, ob diese W\u00f6rter im jeweiligen Tweet vorkommen.\n",
      "Anschlie\u00dfend werden die Tweets in Trainings- und Testset aufgeteilt. Der Klassifizierer soll anhand des belabelten Trainingsset trainiert werden und auf  Basis der f\u00fcr die Labels vorkommenden Features dann die Labels der Tweets im Testset sch\u00e4tzen. \n",
      "\n",
      "Bei der Bestimmung der Gr\u00f6\u00dfe der Sets ist zu beachten, dass ein gro\u00dfes Trainingsset das Modell verbessert, ein gro\u00dfes Testset den Test aber verl\u00e4sslicher werden l\u00e4sst. Das Verh\u00e4ltnis der Tweets in Trainings- und Testset betr\u00e4gt hier in etwa 2:1. Die Fallzahlen sollten zwar f\u00fcr die Klassifizierung ausreichen, im Anhang  wird aber dennoch ein Cross-Validation-Verfahren dargestellt."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def tweet_features(tweet):\n",
      "    tweet_words = set(tweet)\n",
      "    features = {}\n",
      "    for word in word_list:\n",
      "        features['contains(%s)' % word] = (word in tweet_words)\n",
      "    return features\n",
      "\n",
      "train_set =  apply_features(tweet_features, sentiment_sets[:10000])\n",
      "test_set = apply_features(tweet_features, sentiment_sets[10000:])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Modell trainieren und \u00fcberpr\u00fcfen"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Das Modell wird nun anhand des Trainingssets trainiert. Anschlie\u00dfend wird der Klassifikator f\u00fcr das Testset eingesetzt. Mit einer Genauigkeit von 87,94% sch\u00e4tzt das Modell f\u00fcr knapp neun von zehn F\u00e4llen das richtige Label.\n",
      "Unter der Genauigkeit sind die Features abgebildet, die f\u00fcr das Modell den gr\u00f6\u00dften Informationsgehalt aufweisen. Dies wird in Form von Likelihood-Ratios dargestellt. Falls ein Tweet beispielsweise das Wort \"bitch\" enth\u00e4lt, so betr\u00e4gt das Wahrscheinlichkeitsverh\u00e4ltnis f\u00fcr ein negatives Label 183.6 zu 1. \n",
      "\n",
      "Da einige der informativsten Eigenschaften auch in der Liste f\u00fcr die Belabelung der Tweets enthalten waren, ist die hohe Genauigkeit des Klassifikators nicht verwunderlich. Interessant sind eher Begriffe, die nicht in der Evaluationsliste enthalten waren. Hier fallen insbesondere \"bieberannual\", \"retweet\" und \"1999\" auf. \"retweet\" erscheint als plausibler Indikator f\u00fcr positive Beitr\u00e4ge, da vermutlich h\u00e4ufiger als positive wahrgenommene Beitr\u00e4ge geteilt werden. Zum Verst\u00e4ndnis des hohen Informationsgehalt der beiden anderen Begriffe war ein Einblick in die gesammelten Tweets notwendig. Es stellte sich heraus, dass \"1999\" in einer Reihe von Tweets verwendet wurde, welche sich thematisch mit dem Fu\u00dfballspiel zwischen Deutschland und Brasilien im Jahr 1999 befassen. Einige dieser Tweets sind im Anhang abgebildet.\n",
      "\n",
      "Der hohe Informationsgehalt von \"bieberannual\" ist auf einen Spamaccount mit selbiger Bezeichnung zur\u00fcckzuf\u00fchren. S\u00e4mtliche Beitr\u00e4ge dieses Spamaccounts sind durch die vorhergegangene Belabelung der Tweets als positiv klassiert worden. In einem Versuch zur Modellverbesserung im Anhang wurden diese Beitr\u00e4ge von den Analysen ausgeschlossen.\n",
      "Anschlie\u00dfend sind noch zwei Tests mit manuell eingegebenen Features abgebildet. Der Klassifikator sch\u00e4tzt f\u00fcr beide Tests das korrekte Label."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
      "print \"Labels:      \" + str(classifier.labels())\n",
      "print \"Genauigkeit: \" + str(nltk.classify.accuracy(classifier, test_set))\n",
      "print classifier.show_most_informative_features(20)\n",
      "print \"Test positiv:  \" + str(classifier.classify(tweet_features([\"feel\", \"good\", \"mood\"])))\n",
      "print \"Test negativ:  \" + str(classifier.classify(tweet_features([\"sad\", \"sucks\", \"death\"])))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Labels:      ['positive', 'negative']\n",
        "Genauigkeit: 0.879355629487"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Most Informative Features\n",
        "         contains(bitch) = True           negati : positi =    183.6 : 1.0\n",
        "          contains(gain) = True           positi : negati =     84.4 : 1.0\n",
        "       contains(follows) = True           positi : negati =     75.7 : 1.0\n",
        "      contains(retweets) = True           positi : negati =     73.4 : 1.0\n",
        "          contains(fuck) = True           negati : positi =     73.2 : 1.0\n",
        "  contains(bieberannual) = True           positi : negati =     62.8 : 1.0\n",
        "       contains(retweet) = True           positi : negati =     53.0 : 1.0\n",
        "          contains(shit) = True           negati : positi =     47.2 : 1.0\n",
        "       contains(fucking) = True           negati : positi =     35.1 : 1.0\n",
        "          contains(damn) = True           negati : positi =     34.0 : 1.0\n",
        "          contains(hate) = True           negati : positi =     33.6 : 1.0\n",
        "           contains(ass) = True           negati : positi =     30.3 : 1.0\n",
        "         contains(bored) = True           negati : positi =     30.0 : 1.0\n",
        "      contains(birthday) = True           positi : negati =     29.3 : 1.0\n",
        "          contains(1999) = True           negati : positi =     28.7 : 1.0\n",
        "        contains(killed) = True           negati : positi =     28.7 : 1.0\n",
        "         contains(sucks) = True           negati : positi =     26.0 : 1.0\n",
        "        contains(outfit) = True           negati : positi =     26.0 : 1.0\n",
        "         contains(great) = True           positi : negati =     24.8 : 1.0\n",
        "        contains(thanks) = True           positi : negati =     24.5 : 1.0\n",
        "None\n",
        "Test positiv:  positive\n",
        "Test negativ:  negative\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Fehleranalyse"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Abschlie\u00dfend stellt sich noch die Frage, in welchen F\u00e4llen das Modell keine korrekten Vorhersagen mehr liefert. Im n\u00e4chsten Abschnitt werden deshalb solche Fehler \u00fcberpr\u00fcft. Im Idealfall sollte dieses Verfahren zun\u00e4chst mit verschiedenen Development- und Trainingssets und anschlie\u00dfend mit einem bis dahin unbenutzten Testset durchgef\u00fchrten werden. Aus Platzgr\u00fcnden beschr\u00e4nkt sich die Analyse hier auf einen Vorgang. \n",
      "\n",
      "Unten sind exemplarisch f\u00fcnf Tweets abgebildet, bei denen das Modell eine falsche Sch\u00e4tzung abgegeben hat. Hier f\u00e4llt es jedoch schwer ein eindeutiges Muster zu erkennen. Auff\u00e4llig ist vorallem der hohe Anteil an Begriffen, die nicht in der Evaluationsliste f\u00fcr die Belabelung enthalten waren."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_tweets = sentiment_sets[10000:]\n",
      "devtest_tweets = sentiment_sets[3000:10000]\n",
      "#test_tweets = sentiment_sets[:3000]\n",
      "\n",
      "train_set = apply_features(tweet_features, train_tweets)\n",
      "devtest_set = apply_features(tweet_features, devtest_tweets)\n",
      "#test_set = apply_features(tweet_features, test_tweets)\n",
      "\n",
      "classifier = nltk.NaiveBayesClassifier.train(train_set) \n",
      "print nltk.classify.accuracy(classifier, devtest_set) \n",
      "\n",
      "errors = []\n",
      "for (tweet, sentiment) in devtest_tweets:\n",
      "    guess = classifier.classify(tweet_features(tweet))\n",
      "    if guess != sentiment:\n",
      "        errors.append( (sentiment, guess, tweet) )\n",
      "for (sentiment, guess, tweet) in sorted(errors[0:5]):\n",
      "    print \"correct: \" + str(sentiment) + \"  guess: \" + str(guess) +  \"\\n tweet: \" + str(tweet)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.865714285714\n",
        "correct: negative  guess: positive\n",
        " tweet: [u'reno_yo', u'but', u'ruin']"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "correct: negative  guess: positive\n",
        " tweet: [u'rt', u'goofyaims', u'does', u'mean', u'get', u'dizzy', u'everytime', u'you', u'get', u'the', u'bed', u'\\U0001f615']\n",
        "correct: negative  guess: positive\n",
        " tweet: [u'rt', u'ram_guha', u'amit', u'shah', u'heading', u'bjp', u'all', u'time', u'low', u'the', u'criminal', u'justice', u'system', u'writes', u'ranaayyub', u'http', u'//t.co/y26vyhtqlq']\n",
        "correct: negative  guess: positive\n",
        " tweet: [u'think', u'have', u'sex', u'lot', u'people', u'you', u'go', u'greazy', u'you', u'like', u'a', u'worthless', u'slut']\n",
        "correct: positive  guess: negative\n",
        " tweet: [u'gruelling', u'pt', u'sesh', u'craig', u'mclub_stoke', u'seems', u'be', u'put', u'my', u'paces', u'keeps', u'members', u'amused', u'commit', u'fitness', u'training', u'change']\n"
       ]
      }
     ],
     "prompt_number": 15
    }
   ],
   "metadata": {}
  }
 ]
}