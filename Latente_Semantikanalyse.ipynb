{
 "metadata": {
  "name": "",
  "signature": "sha256:a62fedcdd74fc9e7a415ba2fd965da50bce820b53ff99027168138c618a2396e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Quantitative Textanalyse in Python:\n",
      "Bericht 3"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<b>Aufgabenstellung</b>:\n",
      "\n",
      "- Texte aussuchen\n",
      "- LSA Modell konstruieren\n",
      "- Ergebnisse inhaltlich interpretieren"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      " Beschreibung der latenten Semantikanalyse und Vorstellung der Texte"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "F\u00fcr den dritten Bericht wird eine latente Semantikanalyse, kurz <i>LSA</i>, zu Filmbewertungen durchgef\u00fchrt. <br> Ein Hauptproblem bei der Erfassung der Bedeutung von Texten besteht darin, dass diese nicht einfach durch die einzelnen Textelemente erfasst werden kann. Textelemente an sich beinhalten nur unzureichende Informationen \u00fcber die Semantik in Texten. So k\u00f6nnen unterschiedliche Textelemente beispielsweise die selbe Bedeutung haben (-> <i>Synonyme</i>). Ebenso kann jedoch ein Textelement je nach eingebettetem Kontext auch verschiedene Bedeutungen haben, wie etwa der Begriff <i>Bank</i> semantisch sowohl f\u00fcr eine Sitzgelegenheit als auch f\u00fcr ein Kreditinstut stehen kann (-> <i>Polysemie</i>). Mithilfe von LSA wird versucht, die zugrundeliegende und latente, also nicht direkt beobachtbare Bedeutung eines Textes zu erfassen. Hierf\u00fcr werden Textelemente und Texte in einen Vektorraum projeziert und einer Dimensionsreduktion unterzogen. <br>\n",
      "So soll es in der hier durchgef\u00fchrten LSA letztendlich m\u00f6glich sein, neue, im verwendeten Korpus nicht enthaltene Texte auf \u00c4hnlichkeit zu bestehenden Texten zu untersuchen, um Filmbewertungen mit der h\u00f6chsten \u00c4hnlichkeit zu identifizieren.\n",
      "Bestandteil der Analyse sind \u00fcber [66.000 Reviews](http://www.dropbox.com/s/k2vyti6pxzmmr73/imdb-reviews.txt) in gr\u00f6\u00dftenteils englischer Sprache, die aus der Online-Datenbank <i>IMDb</i> extrahiert wurden. \n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Vorbereitungen"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Die Reviews werden zun\u00e4chst eingelesen und in einer Liste gespeichert, welche wiederum Listen der einzelnen Reviews enth\u00e4lt."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%cd \"E:\\Dropbox\\Soziologie Master\\Quantitative Textanalysen mit Python\\Berichte\\3. Bericht\"\n",
      "import csv\n",
      "import nltk\n",
      "import pickle\n",
      "from nltk.corpus import stopwords\n",
      "from gensim import corpora, models, similarities\n",
      "import codecs\n",
      "\n",
      "def saveobject(obj, filename):\n",
      "    with open(filename, 'wb') as output:\n",
      "        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)\n",
      "\n",
      "def loadobject(filename):\n",
      "    with open(filename, 'rb') as f:\n",
      "        output = pickle.load(f)\n",
      "        return output"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "E:\\Dropbox\\Soziologie Master\\Quantitative Textanalysen mit Python\\Berichte\\3. Bericht\n"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reviews = []\n",
      "inputfile = codecs.open(\"imdb-reviews.txt\", encoding='utf-8')\n",
      "once = []\n",
      "for line in inputfile:\n",
      "    reviews.append([line])   \n",
      "inputfile.close()\n",
      "reviews = [review for review in reviews if review !=[]]\n",
      "reviews = [review for review in reviews if review !=[\"\\n\"]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Insgesamt wurden 66.066 Reviews eingelesen. Der nachfolgende Output zeigt eines dieser Reviews."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(reviews)\n",
      "print reviews[1337]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "66066\n",
        "[u\"1336 1336 Three young doctors with markedly different backgrounds and motives work in the small Texas town of Cutter, 60 miles from Houston. When they run into medical problems their local facility can't handle, they contact the Texas Medical Center in Houston. \\n\"]\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Nun werden die Reviews tokenisiert und von Stoppw\u00f6rtern bereinigt. Zur Verbesserung des sp\u00e4ter erstellten Modells werden hier zus\u00e4tzlich Tokens entfernt, die in allen Texten nur einmal vorkommen."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "engstopwords = stopwords.words('english')\n",
      "tokens = [[token.lower() for token in nltk.word_tokenize(review[0])\n",
      "           if token.lower() not in engstopwords and token.isalnum()]\n",
      "          for review in reviews]\n",
      "\n",
      "def onlyonce(list):\n",
      "    dic = {}\n",
      "    once = {}\n",
      "    for review in list:\n",
      "        for token in review:\n",
      "            if token not in dic:\n",
      "                dic[token] = 1\n",
      "            else:\n",
      "                dic[token] +=1\n",
      "    for key, value in dic.iteritems():\n",
      "        if value ==1:\n",
      "            once[key] = True\n",
      "    return once\n",
      "only_once = onlyonce(tokens)\n",
      "\n",
      "tokens = [[token for token in text[2:] if token not in only_once]\n",
      "          for text in tokens]\n",
      "saveobject(tokens, \"review_tokens\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 45
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Erstellung eines Diktion\u00e4rs und Transformation der Reviews"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Im n\u00e4chsten Schritt wird ein Gensim-Diktion\u00e4r auf Basis der Tokens erstellt. Anschlie\u00dfend werden die Reviews zu numerischen Vektoren transformiert. Hier wird jeder Token einer id in Form einer Zahl zugeordnet und die H\u00e4ufigkeit eines Wortes im jeweiligen Dokument gespeichert. Diese Umformung wird in Vorbereitung f\u00fcr eine Singul\u00e4rwertzerlegung durchgef\u00fchrt.\n",
      "\n",
      "Im folgenden Output wird die Vektordarstellung eines Reviews in Form von Tupeln aus der id eines Tokens und der H\u00e4ufigkeit des Tokens im Review abgebildet."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%cd \"E:\\Dropbox\\Soziologie Master\\Quantitative Textanalysen mit Python\\Berichte\\3. Bericht\"\n",
      "tokens = loadobject(\"review_tokens\")\n",
      "dictionary = corpora.Dictionary(tokens)\n",
      "dictionary.save('moviereviews.dict')\n",
      "\n",
      "corpus = [dictionary.doc2bow(token) for token in tokens]\n",
      "print corpus[1337]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "E:\\Dropbox\\Soziologie Master\\Quantitative Textanalysen mit Python\\Berichte\\3. Bericht\n",
        "[(6, 1), (115, 1), (411, 1), (535, 1), (556, 1), (570, 1), (572, 1), (700, 1), (709, 1), (1031, 1), (1207, 1), (1250, 2), (1686, 1), (1689, 1), (1751, 1), (2404, 1), (2967, 1), (4029, 1), (4205, 1), (5355, 1), (6559, 1), (6565, 2), (12209, 1), (13433, 1)]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "TFIDF-Gewichtung"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Nachdem Tokens unterschiedlich h\u00e4ufig in den Reviews vorkommen, bietet es sich an, die Tokens nach ihren H\u00e4ufigkeiten zu gewichten. So sollte etwa ein Begriff der lediglich in f\u00fcnf Prozent der Reviews vorkommt f\u00fcr die  Singul\u00e4rwertzerlegung st\u00e4rker gewichtet werden als ein Begriff der in 90% der Reviews enthalten ist. F\u00fcr diesen Zweck wird eine TFIDF-Gewichtung durchgef\u00fchrt, welche sich aus folgender Formel ergibt:\n",
      "\n",
      "\\begin{equation}\n",
      "TFIDF_{i,j}= N_{i,j} * log\\left (D / D_{i}  \\right )\n",
      "\\end{equation}\n",
      "\n",
      "Hierbei stehen: \n",
      "\n",
      "- <i>Ni,j</i> f\u00fcr die H\u00e4ufigkeit eines Wortes <i>i</i> in Dokument <i>j</i>, \n",
      "- <i>D</i> f\u00fcr die Anzahl der Dokumente \n",
      "- und <i>Di</i> f\u00fcr die Anzahl der Dokumente in denen Wort <i>i</i> enthalten ist.\n",
      "\n",
      "\u00dcber den Logarithmus Dualis wird die inverse Dokumentenh\u00e4ufigkeit gebildet."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tfidf = models.TfidfModel(corpus)\n",
      "corpus_tfidf = tfidf[corpus]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Singul\u00e4rwertzerlegung"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Schlie\u00dflich wird nach den Vorbereitungen der eigentliche Hauptbestandteil der LSA durchgef\u00fchrt: die Dimensionsreduktion durch Singul\u00e4rwertzerlegung. Mit Hilfe der Singul\u00e4rwertzerlegung kann die erstellte $n \\times m$ Dokument/Wort-Matrix  <i>A</i> in ein Produkt aus drei Matrizen zerlegt werden\n",
      "\n",
      "\\begin{equation}\n",
      "A = U \\Sigma V^* \\;\n",
      "\\end{equation}\n",
      "wobei gilt: <br>\n",
      "\n",
      "- $U$    = eine orthogonale $n \\times n$ Matrix\n",
      "- $V^*$ = die Transposition einer orthogonalen $m \\times m$ Matrix $V$\n",
      "- $\\Sigma$   = eine $n \\times m$ Matrix, die auf ihrer Diagonalen die Singul\u00e4rwerte enth\u00e4lt\n",
      "\n",
      "Die Singul\u00e4rwerte aus $\\Sigma$ stellen eine dimensionsreduzierte Version der Dokument/Wort-Matrix dar und erlauben die bestm\u00f6gliche Rekonstruktion der Matrix mit m\u00f6glichst wenig Informationen. Somit werden starke Beziehungen betohnt und unwichtige vernachl\u00e4ssigt. <br>\n",
      "Die Anzahl der zu bildenden Dimensionen kann manuell bestimmt werden. Bei zu wenigen Dimensionen werden m\u00f6glicherweise wichtige Bedeutungsmuster nicht ber\u00fccksichtigt und f\u00fcr zu viele Dimensionen verschlechtern unwichtige Begriffe das Modell. In diesem Beispiel wurde die Anzahl der Dimensionen auf $n=200$ festgesetzt. <br>\n",
      "Der Output zeigt die f\u00fcnf einflussreichsten W\u00f6rter f\u00fcr eine ausgew\u00e4hlte Dimension des Modells."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lsi = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=200)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print lsi.show_topic(20, topn=5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(-0.36616954984968297, u'town'), (0.3549438675519318, u'man'), (0.25768942490782371, u'new'), (-0.20541965212554339, u'small'), (0.19164666837957398, u'york')]\n"
       ]
      }
     ],
     "prompt_number": 62
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "\u00c4hnlichkeitsabfragen"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Bisher wurden die einzelnen Texte vektorisiert, gewichtet und einer Singul\u00e4rwertzerlegung unterzogen. Auf Basis des dimensionsreduzierten Modells k\u00f6nnen nun \u00c4hnlichkeiten zwischen neuen Texten und den im Korpus enthaltenen Texten berechnet werden. Die \u00c4hnlichkeit zwischen Texten wird hier durch die <i>Kosinus-\u00c4hnlichkeit</i> bestimmt. Die <i>Kosinus-\u00c4hnlichkeit</i> beruht auf der Berechnung des Kosinus zweier Vektoren und kann Werte von -1 bis 1 annehmen, wobei 1 als maximale \u00c4hnlichkeit interpretiert werden kann.\n",
      "\n",
      "Die nachfolgende Funktion beinhaltet folgende Schritte zur Abgleichung von \u00c4hnlichkeiten:\n",
      "\n",
      "-  Falten des neuen Dokuments in den Vektorraum\n",
      "-  Transformierung und Indizierung des Korpus\n",
      "-  \u00c4hnlichkeitsabfrage des neuen Dokuments zum Korpus\n",
      "-  Sortierung der \u00c4hnlichkeiten und Zusammenf\u00fchrung mit den zugeh\u00f6rigen Dokumenten\n",
      "-  Ausgabe einer festgelegten Anzahl der \u00e4hnlichsten Dokumente\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def cos_sim(doc, ndocs=3):\n",
      "    vec_bow = dictionary.doc2bow(doc.lower().split())\n",
      "    vec_lsi = lsi[vec_bow]\n",
      "    index_tfidf = similarities.MatrixSimilarity(lsi[corpus_tfidf])\n",
      "    sims = index_tfidf[vec_lsi]\n",
      "    sims = sorted(zip(sims, reviews), reverse=True)\n",
      "    for review in sims[:ndocs]:\n",
      "        print review\n",
      "  "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 52
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Abschlie\u00dfend wird zur Demonstration eines Anwendungsbeispiels f\u00fcr die latente Semantikanalyse die Funktion f\u00fcr zwei \u00c4hnlichkeitsabfragen verwendet. Abgebildet werden jeweils die \u00e4hnlichsten Reviews und deren Kosinuswerte.\n",
      "\n",
      "Die erste Abfrage sollte eine hohe \u00c4hnlichkeit zu Reviews aufweisen die von Filmen aus den Genres Liebeskom\u00f6die oder romantische Kom\u00f6die handeln, was durch eine Einsicht in die Reviews best\u00e4tigt wird: Jedes der drei Reviews beruht aller Wahrscheinlichkeit nach auf einem Film, in dem Liebesbeziehungen eine gro\u00dfe Rolle spielen."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cos_sim(\"charming love romantic relationship\", 3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:gensim.similarities.docsim:scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(0.72404712, [u\"34505 34505 Olli Meri, a reporter in a sensation magazine, finds out that the physiotherapist Eila has a secret relationship with MP Arvo Lamminp\\xe4\\xe4. Meri exposes the love affair in his magazine, but while MP's popularity only grows, Eila is scorned and loses her job and apartment. Meri helps her to find new work but continues to publish stories about Eila. Eventually Meri falls in love with Eila who responds with mixed feelings of hate, love and revenge. \\n\"])\n",
        "(0.69287884, [u'48748 48748 This costumed love fantasy derived from the Arabian Nights tells of Laila (Zubeida), a gypsy dancer who falls in love with the Persian soldier Asghar (Desa). The villain who lusts after Laila, is Sardar Sagi (Gulab), right-hand man to the grand vizir (Joshi) who has political ambitions of his own. \\n'])\n",
        "(0.69221258, [u\"17645 17645 A dashing officer of the guard and romantic poet, Cyrano de Bergerac falls in love with his cousin Roxane without her knowing. His one fault in his life, he feels, is his large nose and although it may have been a forming influence in his rapier-sharp wit, he believes that Roxane will reject him. He resorts to writing letters to her on behalf of one of his cadets, Christian, who is also in love with Roxane but just doesn't know how to tell her. She falls for the poetic charm of the letters but believes that they were written by Christian. The classic, tragic story brought to the screen once again. This French film tells the tale of the soulful poet/philosopher and expert duelist named Cyrano who falls in love with the fair Roxanne, but is ashamed to woo her because of his huge nose. Instead he writes love letters for slow-witted, but handsome Christian in order to win her hand for him. She falls deeply in love with the author, but doesn't know they were written by Cyrano. \\n\"])\n"
       ]
      }
     ],
     "prompt_number": 65
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Die zweite Abfrage sollte eine hohe \u00c4hnlichkeit mit Reviews zu Action- oder Kriegsfilmen aufweisen, was ebenfalls durch einen Einblick in die Ausgabe best\u00e4tigt werden kann. <br>Interessant sind hier insbesondere das siebte sowie das zehnte abgebildete Review. Keiner dieser beiden Texte enh\u00e4lt einen exakten Begriff aus der Abfrage. Lediglich der Begriff <i>fight</i> ist in diesen Reviews enthalten. Hier zeigt sich die St\u00e4rke der latenten Semantikanalyse: die zugrundeliegende Bedeutung des Textes wurde erfasst und in Zusammenhang mit Texten \u00e4hnlicher Bedeutung gebracht. Eine (triviale und mittlerweile \u00e4u\u00dferst praxisferne) Suchanfrage, die als Kriterium lediglich das Vorhandensein eines Begriffs aus der Abfrage verwendet, h\u00e4tte die beiden Texte nicht ausgegeben."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cos_sim(\"fighting guns action\", 10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:gensim.similarities.docsim:scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(0.49205062, [u'35181 35181 In the grand tradition of the lone hero who mysteriously appears in a town desperate for help (think \"Shane, \"Billy Jack\", \"James Bond\" and \"Chinese Connection\"), having survived a war and now serving the government as an undercover agent, Danny Silva (Fabian Carrillo) takes on his biggest foe yet: the street gangs that have taken over his neighborhood. Unwilling to play by the rules set down by the criminals, Silva forgoes the use of guns and decides to battle the thugs with the strength of his fists, spirit and willpower, turning himself into a real-life, modern-day superhero. Packed with pulse pounding, adrenaline-filled action; \"Latin Dragon\" gives us our first mainstream Latino martial arts action hero. \\n'])\n",
        "(0.46823484, [u'11607 11607 Blade and Sword, the first PC Game title which combines Diablo-like action elements and Street Fighter arcade combat together, ushers in a new era in computer Role-Playing, that of the Action-RPG with amazing action and breath-taking martial arts from ancient China. \\n'])\n",
        "(0.46785885, [u'18427 18427 The government\\'s new \"urban renewal\" program results in street gangs fighting each other for control of the cities. While most inner-city residents flee from the fighting, a determined factory owner stays where he is and prepares to fight the gangs for control of his building. \\n'])\n",
        "(0.46542457, [u'59851 59851 The Toxic Avenger is lured to Tokyo, Japan by the evil corporation Apocalypse Inc. So while the Toxic Avenger is fighting crime in Tokyo, Apocalypse Inc. spread evil in Tromaville. \\n'])\n",
        "(0.46441066, [u'11890 11890 Martial arts action film finds a retired detective returning to action to stop a martial arts master with steel fingers who is killing champions from all sports. \\n'])\n",
        "(0.44107977, [u'20866 20866 An international terrorist organisation plans to take over the world. Agent Ara a super cop is sent out to bring in the evil Shek. Dead or alive! This leads to some of the best martial arts action scenes ever shot. Without the use of CGI and wires. \\n'])\n",
        "(0.43825638, [u\"33744 33744 EastSide boxing champion (Leo Gorcey) has been challenged to fight the West Side champ but is kidnapped before the match. Leo's friend (Bobby Jordan) takes his place and wins the fight only to have Leo think that Bobby was responsible for his kidnapping. \\n\"])\n",
        "(0.43593383, [u'50256 50256 This film shows a most exciting Graeco-Roman Wrestling match between two of the most skillful \"Knights of the Mat\" and is full of action from start to finish; every muscle stands out in relief as the Gladiators battle for supremacy. The fall is finally won by Roeber after a hard fought contest which keeps the spectactors in a fever of excitement. The match took place in a large Amphitheatre and the referee, timekeeper, judges and seconds who are all well known sporting men, form an animated background to the scene. Photography and action throughout are perfect. \\n'])\n",
        "(0.43470556, [u'16347 16347 You are Havoc, a GDI commando who GDI soldiers look up to. Set during Command & Conquer, you blast and kill every NOD soldier. Instead of controlling your units, you are actually fighting Nod. \\n'])\n",
        "(0.43362144, [u\"30207 30207 An exotic, legendary battle between the forces of good and evil comes to life as the celebrated disciples of the Shaolin Temple -- monks who practice a lethal and spiritual form of martial arts -- fight the evil followers of China's Manchu rulers. \\n\"])\n"
       ]
      }
     ],
     "prompt_number": 68
    }
   ],
   "metadata": {}
  }
 ]
}